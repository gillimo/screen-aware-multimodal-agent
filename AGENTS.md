# Mission Learning Statement
- Mission: Build a screen-aware local multimodal agent with perception, planning, and humanized input.
- Learning focus: multimodal perception, state modeling, and robust action execution loops.
- Project start date: 2026-01-06 (inferred from earliest git commit)

# AGENTS.md

Purpose: define how to run the screen-aware local multimodal agent project and how to sign work.

- Project scope: `OneDrive/Desktop/projects/agentosrs`.
- Sign-in: register in `docs/LOGBOOK.md` before edits; sign docs/logs with handle + date.
- Entry points:
  - CLI: `python run_app.py <command>`
  - GUI: `python run_app.py gui`
- Logs: write to `logs/run_*.log` or `logs/demo_*.log` when enabled.
- Data: editable stubs live in `data/` (state, ratings, dependencies).

Signed: Codex (2026-01-06)
